# @package _global_

#encoder_checkpoint: results/iql_fenc/lightning_logs/version_1_encoder/last.ckpt
#discriminator_checkpoint: results/iql_fenc/lightning_logs/version_2_discriminator/last.ckpt

algo:
  config:

    dataset_files:
      - output/recordings/mimic_train_iql/RL_Avatar_Atk_2xCombo01_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_Atk_Kick_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_Atk_ShieldSwipe01_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_Counter_Atk03_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_Idle_Ready_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_RunBackward_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_RunForward_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_RunLeft_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_RunRight_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_TurnLeft90_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_TurnLeft180_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_TurnRight90_Motion/dataset.hdf5
      - output/recordings/mimic_train_iql/RL_Avatar_TurnRight180_Motion/dataset.hdf5

    demo_dataset_files:
      - output/recordings/mimic_eval_iql/RL_Avatar_Atk_2xCombo01_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_Atk_Kick_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_Atk_ShieldSwipe01_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_Counter_Atk03_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_Idle_Ready_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_RunBackward_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_RunForward_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_RunLeft_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_RunRight_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_TurnLeft90_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_TurnLeft180_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_TurnRight90_Motion/dataset.hdf5
      - output/recordings/mimic_eval_iql/RL_Avatar_TurnRight180_Motion/dataset.hdf5

    models:
      terrain_models:
        mlp: null
        transformer: null
    # Setup discriminator structure
    actor:
      _target_: phys_anim.agents.models.actor.ActorFixedSigma
      _recursive_: false
      config:
        initializer: default
        mu_model:
          _target_: phys_anim.agents.models.mlp.MultiHeadedMLP
          _recursive_: false
          config:
            initializer: ${algo.config.actor.config.initializer}
            units: [1024, 1024,512]
            activation: ${algo.config.actor.config.activation}
            normalize_obs: ${algo.config.normalize_obs}
            obs_clamp_value: ${algo.config.obs_clamp_value}
            use_layer_norm: ${algo.config.actor.config.use_layer_norm}
            terrain_model: ${algo.config.models.terrain_models.mlp}
            extra_inputs:
              terrain: ${..terrain_model}
              latents:
                _target_: phys_anim.agents.models.common.Flatten
                config:
                  normalize_obs: False
                  obs_clamp_value: ${algo.config.obs_clamp_value}
                num_in: ${sum:${algo.config.infomax_parameters.latent_dim}}
                num_out: ${.num_in}
            latent_dim: ${algo.config.infomax_parameters.latent_dim}
        init_logstd: -2.9
        learnable_sigma: false
        sigma_schedule: null
        use_layer_norm: false
        activation: relu

    critic_s:
      _target_: phys_anim.agents.models.critic.CriticMLP
      _recursive_: False
      config:
        initializer: default
        units: [1024, 1024, 512 ]
        activation: relu
        normalize_obs: ${algo.config.normalize_obs}
        obs_clamp_value: ${algo.config.obs_clamp_value}
        use_layer_norm: False
        extra_inputs:
          latents:
            _target_: phys_anim.agents.models.common.Flatten
            config:
              normalize_obs: False
              obs_clamp_value: ${algo.config.obs_clamp_value}
            num_in: ${sum:${algo.config.infomax_parameters.latent_dim}}
            num_out: ${.num_in}

    critic_sa:
      _target_: phys_anim.agents.models.critic.CriticMLP
      _recursive_: False
      config:
        initializer: default
        units: [ 1024, 1024, 1024, 1024, 512 ]
        activation: relu
        normalize_obs: ${algo.config.normalize_obs}
        obs_clamp_value: ${algo.config.obs_clamp_value}
        use_layer_norm: False
        extra_inputs:
          actions:
            _target_: phys_anim.agents.models.common.Flatten
            config:
              normalize_obs: False
              obs_clamp_value: ${algo.config.obs_clamp_value}
            num_in: ${robot.number_of_actions}
            num_out: ${.num_in}
          latents:
            _target_: phys_anim.agents.models.common.Flatten
            config:
              normalize_obs: False
              obs_clamp_value: ${algo.config.obs_clamp_value}
            num_in: ${sum:${algo.config.infomax_parameters.latent_dim}}
            num_out: ${.num_in}

    discriminator:
      _target_: phys_anim.agents.models.discriminator.JointDiscMLP
      _recursive_: false
      config:
        initializer: default
        units: [ 1024, 1024, 512 ]
        discriminator_obs_historical_steps: ${env.config.discriminator_obs_historical_steps}
        activation: relu
        normalize_obs: ${algo.config.normalize_obs}
        obs_clamp_value: ${algo.config.obs_clamp_value}
        use_layer_norm: false
        extra_inputs: null
        latent_dim: ${algo.config.infomax_parameters.latent_dim}

    encoder:
      _target_: phys_anim.agents.models.mlp.MLP_WithNorm
      _recursive_: false
      config:
        initializer: default
        units: [ 1024, 1024, 512 ]
        discriminator_obs_historical_steps: ${env.config.discriminator_obs_historical_steps}
        activation: relu
        normalize_obs: ${algo.config.normalize_obs}
        obs_clamp_value: ${algo.config.obs_clamp_value}
        use_layer_norm: false
        extra_inputs: null
        latent_dim: ${algo.config.infomax_parameters.latent_dim}

    decoder:
      _target_: phys_anim.agents.models.mlp.MLP_WithNorm
      _recursive_: false
      config:
        initializer: default
        units: [ 512, 1024, 1024 ]
        discriminator_obs_historical_steps: ${env.config.discriminator_obs_historical_steps}
        activation: relu
        normalize_obs: ${algo.config.normalize_obs}
        obs_clamp_value: ${algo.config.obs_clamp_value}
        use_layer_norm: false
        extra_inputs: null
        latent_dim: ${algo.config.infomax_parameters.latent_dim}

    actor_optimizer:
      _target_: torch.optim.Adam
      lr: 2e-5
      betas: [0.9, 0.999]

    critic_optimizer:
      _target_: torch.optim.Adam
      lr: 1e-4
      betas: [0.9, 0.999]

    discriminator_optimizer:
      _target_: torch.optim.Adam
      lr: 1e-4
      betas: [ 0.9, 0.999 ]

    actor_lr_scheduler: null
    critic_lr_scheduler: null

    # ASE parameters
    infomax_parameters:
      latent_dim: [ 64 ]
      latent_types: [ hypersphere ]

      mi_reward_w: [ 0.5 ]
      mi_hypersphere_reward_shift: True

      mi_enc_weight_decay: 0
      mi_enc_grad_penalty: 0

      diversity_tar: 1.
      diversity_bonus: 0.01

      random_latents: True
      latent_steps_min: 1
      latent_steps_max: 150

    #IQL parameters
    expectile: 0.7
    alpha: 1
    batch_size: 16384
    max_epochs: 271
    normalize_obs: True
    obs_clamp_value: null
    discriminator_reward_w: 2.0
    discriminator_grad_penalty: 5
    discriminator_weight_decay: 0.0001
    discriminator_logit_weight_decay: 0.01
    discount: 0.99
    beta: 3 # aka temperatue
    num_env_import: 1

    eval_callbacks: null

    extra_inputs: null

    num_obs_enc_steps: 60

env:
  config:
    # Simulation params
    ## Observations
    humanoid_obs:
      use_max_coords_obs: True
      local_root_obs: True
      root_height_obs: True

    discriminator_obs_historical_steps: 10
    disable_discriminator: False
    discriminator_obs_size_per_step: ${eval:13+2*${robot.dof_obs_size}+${robot.number_of_actions}+3*${robot.num_key_bodies}}

    encoder_future_steps: 2

    ## Motion-related params
    ### Respawn related params
    state_init: Random